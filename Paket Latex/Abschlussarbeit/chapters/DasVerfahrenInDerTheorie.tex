\chapter{Das Verfahren in der Theorie}
In diesem Kapitel wird auf die theoretischen Grundlagen des Verfahrens eingegangen. Es handelt sich dabei um eine Zusammenfassung, welche die wichtigsten Konzepte für das weitere Verständnis aufbereiten soll und beschränkt sich daher auf das Wesentliche. Weiterführende Lektüre, welche für die folgenden Abschnitte auch als Quelle gedient hat, ist unter anderem zu finden bei \cite{Simek:12}, \cite{Mathworks:17b} oder \cite{Rahmann}.

\section{Das mathematische Modell einer Kamera}
Das Lichtschnittverfahren macht sich nicht nur den eingangs erwähnten Laser zu Nutze, sondern nutzt zusätzlich eine Kamera um die räumlichen Informationen des vermessenen Objektes zu rekonstruieren. Die Kamera dient dabei als Betrachter der projizierten Laserlinie. Mathematisch wird hier das Modell einer Lochkamera zugrunde gelegt. Bei diesem Modell wird angenommen, dass Lichtstrahlen, die von einem Objekt reflektiert werden, durch den Fokuspunkt der Kamera fallen, dort gebündelt werden, und anschließend auf der anderen Seite des Fokuspunktes auf eine gegenüberliegende Projektionsfläche geworfen werden. So entsteht auf der Projektionsfläche das invertierte Bild des Objektes. Abb. \ref{fig:lochkamera} verdeutlicht das Modell. 

\begin{figure}
\centering \includegraphics{images/lochkamera.png}
\caption[Modell einer Lochkamera]{Modell einer Lochkamera. Quelle: \cite{Mathworks:17b}}\label{fig:lochkamera}
\end{figure}

Es handelt sich also um eine Projektion vom dreidimensionalen Raum, dem Weltkoordinatensystem, auf eine zweidimensionale Fläche, im Folgenden als Bildebene bezeichnet. Wie diese Projektion stattfindet, hängt vor allem von zwei Kamera-abhängigen Sets an Parametern ab: Den intrinsischen und den extrinsischen Kameraparametern. Erstere hängen lediglich von der Beschaffenheit der Kamera ab und ändern sich nicht wenn die Kamera ihre Position im Raum ändert. Hierunter fallen die Brennweite der Kamera ("`Focal length'' in der oben stehenden Abbildung) sowie der Ursprung des Bildebenenkoordinatensystms. Außerdem wird hierüber eine Scherung des projizierten Bildes bestimmt. Die intrinsischen Parameter können als 

\begin{equation}
K = \begin{pmatrix}
f_x & s & x_0 \\
0 & f_y & y_0 \\
0 & 0 & 1 
\end{pmatrix}
\end{equation}

 in einer Matrix zusammengefasst werden, in welcher \(f_x\) und \(f_y\) für die Brennweite in Pixeln (bei perfekt quadratischen Pixeln gilt \(f_x = f_y\)), \(s\) für die Scherung und \(y_0\) sowie \(x_0\) für die Verschiebung des Bildkoordinatenursprung in \(X\)- und \(Y\)-Richtung in Pixeln stehen. 
\newline
Im Gegensatz dazu definieren die extrinsischen Parameter die Orientierung und die Position der Kamera im Weltkoordinatensystem. Entsprechend werden diese als eine Rotationsmatrix \(R\) und ein Ortsvektor \(T\) ausgedrückt. Dabei handelt es sich bei \(T\) jedoch nicht etwa um die Position der Kamera in Weltkoordinaten, sondern um den Ursprung des Weltkoordinatensystems welcher in dem Koordinatensystem ausgedrückt ist, dessen Ursprung in der Kamera liegt.
\newline
Mithilfe dieser Parameter ergibt sich die Kameramatrix \(P\) als
\begin{equation}
	P = K \big[ R \mid T \big] 
\end{equation}
Sei nun 
\begin{equation}
	\vec{z_{W}} = \left(\begin{array}{c}x\\y\\z\\1\end{array}\right)
\end{equation}
ein Punkt im Weltkoordinatensystem, ausgedrückt in homogenen Koordinaten. Dann lässt sich der projizierte Bildpunkt
\begin{equation}
	\vec{z_{B}} = \left(\begin{array}{c}u\\v\\1\end{array}\right)
\end{equation}
wie folgt berechnen:
\begin{equation}
	\vec{z_{B}} = P * \vec{z_{W}}
\end{equation}


\subsection{Die Kamera Kalibrierung}
\label{subsec:KameraKalibrierungTheorie}

\subsubsection{Das Kalibrierungsmuster}
Um das Lichtschnittverfahren einzusetzen, müssen die internen und die externen Kameraparameter bekannt sein. Dies geschieht in einem Prozess namens Kamerakalibrierung. Dabei wird mit der Kamera ein bestimmtes Muster fotografiert, welches es besonders einfach macht, algorithmisch Punkte in diesem Muster zu bestimmen. Ein üblicher Ansatz ist es, als ein solches Muster ein Schachbrettmuster mit einer bekannten Seitenlänge für die einzelnen Quadrate zu verwenden. So wurde auch in der vorliegenden Arbeit verfahren. Dieses Muster legt in einem bestimmten Punkt den Koordinatenursprung des Weltkoordinatensystems fest und spannt zugleich die X-Y-Ebene auf. Durch die bekannte Seitenlänge können dann die Weltkoordinaten von weiteren Punkten im Muster bestimmt werden. Wenn die Kamera nun ein Bild des Musters gemacht hat, kann aus diesen Punkten eine Menge von Bildpunkten bestimmt werden, deren entsprechende Weltkoordinaten bekannt sind, und die alle auf der X-Y-Ebene liegen. 

\subsubsection{Homographie}
Alle Punkte, die im Kalibrierungsmuster erkannt wurden, befinden sich wie oben beschrieben auf der X-Y-Ebene. Für sie lässt sich also die Z-Koordinate auf null setzen. Die Projektion dieser Punkte vom Weltkoordinatensystem in die Bildebene kann also anstatt von einer Projektion vom 3D- in den 2D-Raum (wie bei anderen Punkten im Weltkoordinatensystem der Fall) als Projektion von einem 2D- in einen anderen 2D-Raum betrachtet werden. Eine solche Projektion kann als invertierbare projektive Transformation in Form einer Transformationsmatrix ausgedrückt werden. Transformationen dieser Art werden auch als Homographie bezeichnet und meistens mit \(H\) notiert. Aus einer einzelnen Fotografie des Kalibrierungsmusters kann eine solche Homographie \(H\) berechnet werden, indem die daraus resultierenden Korrespondenzen zwischen Punkten im Weltkoordinatensystem und ihren Projektionen auf der Bildeben betrachtet werden. Die Berechnung, welche angepasst aus \cite{Kriegman:07} übernommen wurde, läuft wie folgt ab:
\newline
Seien \(\vec{x_w} = \left(x_w y_w z_w\right)^{T}\) ein Punkt auf der Kalibrierungsmusterebene und \(\vec{x_b} = \left(x_b y_b z_b\right)^{T}\) ein Punkt auf der Bildebene, beide in homogenen Koordinaten. Dann gilt für die Homographie \(H\):
\begin{equation}
	H = \begin{pmatrix}
			H_{11} & H_{12} & H_{13} \\
			H_{21} & H_{22} & H_{23} \\
			H_{31} & H_{32} & H_{33}
		\end{pmatrix}
\end{equation}
\begin{equation}
	\left(\begin{array}{c}x_b\\y_b\\z_b\end{array}\right) =  \begin{pmatrix}
			H_{11} & H_{12} & H_{13} \\
			H_{21} & H_{22} & H_{23} \\
			H_{31} & H_{32} & H_{33}
		\end{pmatrix} * \left(\begin{array}{c}x_w\\y_w\\z_w\end{array}\right)
\end{equation}



\subsubsection{Bestimmung der Kameraparamter}
Laut \cite{Zhang:00} und \cite{Rahmann} kann diese Homografie wie folgt bestimmt werden: Sei die Rotationsmatrix \(R = \left(\vec{r_1}\:\vec{r_2}\:\vec{r_3}\right)\) und die Translation \(T = \vec{t}\) dargestellt in ihren Spaltenvektoren. Unter der oben erläuterten Voraussetzung dass sich alle Punkte auf dem Kalibrierungsmuster (und damit auch auf der X-Y-Ebene) befinden gilt für einen solchen beliebigen Punkt \(x_{welt} = (X\:Y\:0\:1)^{T}\) und dessen Projektion auf die Bildebene \(x_{bild} = (U\:V\:1)^{T}\)
\begin{equation}
	x_{bild} = K\left(\:\vec{r_1}\:\vec{r_2}\:\vec{t}\:\right)x_{welt}
\end{equation}
Die Homografie \(H = \left(\vec{h_1}\:\vec{h_2}\:\vec{h_3}\right)\) ergibt sich dann als
\begin{equation}
	\left(\:\vec{h_1}\:\vec{h_2}\:\vec{h_3}\:\right) = \lambda K\left(\:\vec{r_1}\:\vec{r_2}\:\vec{t}\:\right)
\end{equation}
mit \(\lambda\) als Scalar. Es gilt also
\begin{equation}
r_1 = \lambda^{-1} K^{-1} h_1 \;\;,\;\; r_2 = \lambda^{-1} K^{-1} h_2
\end{equation}
Da für \(r_1\) und \(r_2\) gilt, dass sie orthogonal zueinander stehen (\(r_1^Tr_2=0\)) und normalisiert sind (\(\Vert r_1 \Vert = \Vert r_2 \Vert = 1\)) gilt:
\begin{equation}
	h_1^{T} K^{-T} K^{-1} h_2 = 0
\end{equation}
\begin{equation}
	h_1^{T} K^{-T} K^{-1} h_1 = h_2^{T} K^{-T} K^{-1} h_2
\end{equation}
\section{Der Lichschnitt}
TODO